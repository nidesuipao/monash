{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: MASS\n",
      "Loading required package: NLP\n",
      "\n",
      "Attaching package: 'NLP'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    annotate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "library(mvtnorm) # generates multivariate Gaussian sampels and calculate the densities\n",
    "library(ggplot2) # plotting\n",
    "library(reshape2) # data wrangling!\n",
    "library(clusterGeneration) # generates the covariance matrices that we need for producing synthetic data.\n",
    "library(tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. EM define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "hard_em <- function(N, K, D, data)\n",
    "{\n",
    "    # Setting the parameters:\n",
    "    eta.max <- 100      # maximum number of iteratins\n",
    "    epsilon <- 0.01  # termination threshold \n",
    "\n",
    "    # Initialzations:\n",
    "    eta <- 1            # epoch counter\n",
    "    terminate <- FALSE  # termination condition\n",
    "\n",
    "    ## Ramdom cluster initialization:\n",
    "    # set.seed(2) # save the random seed to make the results reproducble\n",
    "    Phi.hat <- 1/K                          # assume all clusters have the same size (we will update this later on)\n",
    "    Nk.hat <- matrix(N/K,nrow = K)          # refer to the above line!\n",
    "    Mu.hat <- matrix(,nrow = K, ncol = D)\n",
    "    \n",
    "    for(k in 1:K)\n",
    "    {\n",
    "        Mu.hat[k,] = colSums(data[((k-1)*N/K+1):(k*N/K), ])\n",
    "        Mu.hat[k,] = Mu.hat[k,] / sum(Mu.hat[k,] )\n",
    "        \n",
    "    }\n",
    "    post <- matrix(,nrow=N, ncol=K)\n",
    "    ### for each cluster k:\n",
    "\n",
    "    # Build the GMM model\n",
    "    Mu.hat.old <- Mu.hat # store the old estimated means\n",
    "    # Main Loop\n",
    "    while (!terminate)\n",
    "    {   \n",
    "\n",
    "        # E step:   \n",
    "        for (k in 1:K){\n",
    "            ## calculate the posterior based on the estimated means,covariance and cluster size:\n",
    "            # post[,k] <- dmvnorm(data, Mu.hat[k,],  matrix(Sigma.hat[k,], ncol=D)) * Nk.hat[k]\n",
    "            \n",
    "            for(n in 1:N)\n",
    "            {\n",
    "                post[n,k] <- Nk.hat[k] / N\n",
    "                \n",
    "                for(d in 1:D)\n",
    "                {\n",
    "                    if(data[n,d] != 0)\n",
    "                    {\n",
    "                        post[n,k] = post[n,k] * Mu.hat[k,d]^data[n,d]\n",
    "                    }\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "        # hard assignments:\n",
    "        max.prob <- apply(post, 1, which.max) # for each point find the cluster with the maximum (estimated) probability\n",
    "        post[] <- 0 # remove points from clusters with lower probabilites\n",
    "        for(j in 1:length(max.prob))\n",
    "        {\n",
    "            post[j,max.prob[j]] <- 1 \n",
    "        }\n",
    "        \n",
    "        # assign each point to the cluster with the highest probability\n",
    "        # M step:\n",
    "        for (k in 1:K)\n",
    "        {\n",
    "            ## recalculate the estimations:\n",
    "            Nk.hat[k] <- sum(post[,k])        # the effective number of point in cluster k\n",
    "            Phi.hat[k] <- sum(post[,k])/N     # the relative cluster size\n",
    "            Mu.hat[k,] <- colSums(data[which(post[,k] == 1),])\n",
    "            Mu.hat[k,] = Mu.hat[k,] / sum(Mu.hat[k,] )\n",
    "        }\n",
    "\n",
    "        \n",
    "        eta <- eta+1\n",
    "\n",
    "        # print(Mu.hat.old)\n",
    "        # check the termination criteria\n",
    "        terminate <- eta > eta.max | sum(abs(Mu.hat.old - Mu.hat)) <= epsilon\n",
    "        \n",
    "        # record the means (neccessary for checking the termination criteria)\n",
    "        Mu.hat.old <- Mu.hat\n",
    "        # print(terminate)\n",
    "    }\n",
    "    for (k in 1:K){\n",
    "        ## calculate the posterior based on the estimated means,covariance and cluster size:\n",
    "        # post[,k] <- dmvnorm(data, Mu.hat[k,],  matrix(Sigma.hat[k,], ncol=D)) * Nk.hat[k]\n",
    "        \n",
    "        for(n in 1:N)\n",
    "        {\n",
    "            post[n,k] <- Nk.hat[k] / N\n",
    "            \n",
    "            for(d in 1:D)\n",
    "            {\n",
    "                if(data[n,d] != 0)\n",
    "                {\n",
    "                    post[n,k] = post[n,k] * Mu.hat[k,d]^data[n,d]\n",
    "                }\n",
    "            } \n",
    "        }\n",
    "    }\n",
    "    # hard assignments:\n",
    "    max.prob <- apply(post, 1, which.max) # for each point find the cluster with the maximum (estimated) probability\n",
    "\n",
    "    print(Nk.hat)\n",
    "    # That's it! Let see how many iterations we had:\n",
    "    cat('maximum number of itterations:',eta,'\\n')\n",
    "    # return (Nk.hat, Mu.hat, Sigma.hat)\n",
    "    return (max.prob )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "soft_em <- function(N, K, D, data)\n",
    "{\n",
    "\n",
    "    # Setting the parameters:\n",
    "    eta.max <- 100      # maximum number of iteratins\n",
    "    epsilon <- 0.01  # termination threshold \n",
    "\n",
    "    # Initialzations:\n",
    "    eta <- 1            # epoch counter\n",
    "    terminate <- FALSE  # termination condition\n",
    "\n",
    "    ## Ramdom cluster initialization:\n",
    "    # set.seed(2) # save the random seed to make the results reproducble\n",
    "    Phi.hat <- 1/K                          # assume all clusters have the same size (we will update this later on)\n",
    "    Nk.hat <- matrix(N/K,nrow = K)          # refer to the above line!\n",
    "    Mu.hat <- matrix(,nrow = K, ncol = D)\n",
    "    \n",
    "    for(k in 1:K)\n",
    "    {\n",
    "        Mu.hat[k,] = colSums(data[((k-1)*N/K+1):(k*N/K), ])\n",
    "        Mu.hat[k,] = Mu.hat[k,] / sum(Mu.hat[k,] )\n",
    "        \n",
    "    }\n",
    "\n",
    "    post <- matrix(,nrow=N, ncol=K)\n",
    "    ### for each cluster k:\n",
    "\n",
    "    # Build the GMM model\n",
    "    Mu.hat.old <- Mu.hat # store the old estimated means\n",
    "    # Main Loop\n",
    "    while (!terminate)\n",
    "    {\n",
    "        # E step:   \n",
    "        for (k in 1:K){\n",
    "            ## calculate the posterior based on the estimated means,covariance and cluster size:\n",
    "            # post[,k] <- dmvnorm(data, Mu.hat[k,],  matrix(Sigma.hat[k,], ncol=D)) * Nk.hat[k]\n",
    "            \n",
    "            for(n in 1:N)\n",
    "            {\n",
    "                post[n,k] <- Nk.hat[k] / N\n",
    "                for(d in 1:D)\n",
    "                {\n",
    "                    if(data[n,d] != 0)\n",
    "                    {\n",
    "                        post[n,k] = post[n,k] * Mu.hat[k,d]^data[n,d]\n",
    "                    }\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "        for(n in 1:N)\n",
    "        {\n",
    "            a = TRUE\n",
    "            for(k in 1:K)\n",
    "            {\n",
    "                if(post[n,k] != 0)\n",
    "                {\n",
    "                    a = FALSE\n",
    "                }\n",
    "            }\n",
    "            if(a)\n",
    "            {\n",
    "                for(k in 1:K)\n",
    "                {\n",
    "                    post[n,k] = 1\n",
    "                }\n",
    "\n",
    "            }\n",
    "        }\n",
    "\n",
    "        post <- post/rowSums(post) # normalization (to make sure post(k) is in [0,1] and sum(post)=1)\n",
    "        \n",
    "        #M step:\n",
    "        for (k in 1:K)\n",
    "        {\n",
    "            ## recalculate the estimations:\n",
    "            Nk.hat[k] <- sum(post[,k])        # the effective number of point in cluster k\n",
    "            Phi.hat[k] <- sum(post[,k])/N     # the relative cluster size\n",
    "            Mu.hat[k,] <- colSums(post[,k] *data)\n",
    "            Mu.hat[k,] = Mu.hat[k,] / sum(Mu.hat[k,] )\n",
    "        }\n",
    "        eta <- eta+1\n",
    "        \n",
    "        # check the termination criteria\n",
    "        terminate <- eta > eta.max | sum(abs(Mu.hat.old - Mu.hat)) <= epsilon\n",
    "        \n",
    "        # record the means (neccessary for checking the termination criteria)\n",
    "        Mu.hat.old <- Mu.hat\n",
    "\n",
    "    }\n",
    "\n",
    "    for (k in 1:K){\n",
    "        ## calculate the posterior based on the estimated means,covariance and cluster size:\n",
    "        # post[,k] <- dmvnorm(data, Mu.hat[k,],  matrix(Sigma.hat[k,], ncol=D)) * Nk.hat[k]\n",
    "        \n",
    "        for(n in 1:N)\n",
    "        {\n",
    "            post[n,k] <- Nk.hat[k] / N\n",
    "            \n",
    "            for(d in 1:D)\n",
    "            {\n",
    "                if(data[n,d] != 0)\n",
    "                {\n",
    "                    post[n,k] = post[n,k] * Mu.hat[k,d]^data[n,d]\n",
    "                }\n",
    "            } \n",
    "        }\n",
    "    }\n",
    "    # hard assignments:\n",
    "    max.prob <- apply(post, 1, which.max) # for each point find the cluster with the maximum (estimated) probability\n",
    "    print(Nk.hat)\n",
    "    # That's it! Let see how many iterations we had:\n",
    "    cat('maximum number of itterations:',eta,'\\n')\n",
    "    return (max.prob)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. load data and run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## read the file (each line of the text file is one document)\n",
    "text <- readLines('./TASK2B.txt')\n",
    "\n",
    "## randomly selet some samples\n",
    "index <- sample(length(text), 400)\n",
    "text <- text[index]\n",
    "\n",
    "## the terms before '\\t' are the lables (the newsgroup names) and all the remaining text after '\\t' are the actual documents\n",
    "docs <- strsplit(text, '\\t')\n",
    "rm(text) # just free some memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# store the labels for evaluation\n",
    "labels <-  unlist(lapply(docs, function(x) x[1]))\n",
    "\n",
    "# store the unlabeled texts    \n",
    "docs <- data.frame(doc_id = seq(1, length(labels)), text = unlist(lapply(docs, function(x) x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "docs <- DataframeSource(docs)\n",
    "docs <- Corpus(docs)\n",
    "# Preprocessing:\n",
    "docs <- tm_map(docs, removeWords, stopwords(\"english\")) # remove stop words (the most common word in a language that can be find in any document)\n",
    "docs <- tm_map(docs, removePunctuation) # remove pnctuation\n",
    "docs <- tm_map(docs, stemDocument) # perform stemming (reducing inflected and derived words to their root form)\n",
    "docs <- tm_map(docs, removeNumbers) # remove all numbers\n",
    "docs <- tm_map(docs, stripWhitespace) # remove redundant spaces \n",
    "\n",
    "# Create a matrix which its rows are the documents and colomns are the words. \n",
    "## Each number in Document Term Matrix shows the frequency of a word (colomn header) in a particular document (row title)\n",
    "dtm <- DocumentTermMatrix(docs)\n",
    "\n",
    "## reduce the sparcity of out dtm\n",
    "dtm <- removeSparseTerms(dtm, 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "m <- as.matrix(dtm)\n",
    "rownames(m) <- 1:nrow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [,1]\n",
      "[1,]   61\n",
      "[2,]  143\n",
      "[3,]  147\n",
      "[4,]   49\n",
      "maximum number of itterations: 13 \n",
      "          [,1]\n",
      "[1,]  74.97359\n",
      "[2,]  52.73963\n",
      "[3,] 256.98845\n",
      "[4,]  15.29833\n",
      "maximum number of itterations: 18 \n"
     ]
    }
   ],
   "source": [
    "col1 = hard_em(dim(m)[1], 4, dim(m)[2], m)\n",
    "col2 = soft_em(dim(m)[1], 4, dim(m)[2], m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV. PCA and plot picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "228"
      ],
      "text/latex": [
       "228"
      ],
      "text/markdown": [
       "228"
      ],
      "text/plain": [
       "[1] 228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p.comp <- prcomp(m)   \n",
    "length(which((col1 == col2) == TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"hard EM Result\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(p.comp$x, col=adjustcolor(col1, alpha=1), pch=16, main='hard EM Result', xlab = 'x1', ylab = 'x2', cex = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"soft EM Result\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(p.comp$x, col=adjustcolor(col2, alpha=1), pch=16, main='soft EM Result', xlab = 'x1', ylab = 'x2', cex = 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
