{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import *\n",
    "from tensorflow import keras\n",
    "from keras.models import *\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn():\n",
    "    def __init__(self, data_path, load_history, img_rows = 32, img_cols = 32):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.data_path = data_path\n",
    "        self.num_class = 100\n",
    "        self.verbose = True\n",
    "        self.load_history = load_history\n",
    "\n",
    "    def data_init(self):\n",
    "        with open(self.data_path + '/train', mode='rb') as file:\n",
    "            batch = pickle.load(file, encoding='latin1')\n",
    "            self.train_data = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "            self.train_label = batch['fine_labels']\n",
    "            self.train_data = np.array((self.train_data))\n",
    "            self.train_label = np.array((self.train_label))\n",
    "            self.train_label = to_categorical(self.train_label, 100)\n",
    "        with open(self.data_path + '/test', mode='rb') as file:\n",
    "            batch = pickle.load(file, encoding='latin1')\n",
    "            self.test_data = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "            self.test_label = batch['fine_labels']\n",
    "            self.test_data = np.array((self.test_data))\n",
    "            self.test_label = np.array((self.test_label))\n",
    "            self.test_label = to_categorical(self.test_label, 100)\n",
    "\n",
    "    def get_base(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(16, 7, activation='relu', padding='valid', kernel_initializer='he_normal', input_shape = (32,32,3)))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "        self.model.add(Conv2D(32, 5, activation='relu', padding='valid', kernel_initializer='he_normal'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(128, activation='relu'))\n",
    "        self.model.add(Dense(100, activation=None))\n",
    "        # if os.path.exists('./model/base.h5') and self.load_history:\n",
    "        #     self.model.load_weights('./model/base.h5',by_name=True,skip_mismatch=True)\n",
    "\n",
    "    def conv_block(self, inputs, filter_num, reduction_ratio, stride=1, name=None, atten = False):\n",
    "        x = inputs\n",
    "        x = Conv2D(filter_num[0], (1, 1), strides=stride, padding='same', name=name + '_conv1')(x)\n",
    "        x = BatchNormalization(axis=3, name=name + '_bn1')(x)\n",
    "        x = Activation('relu', name=name + '_relu1')(x)\n",
    "\n",
    "        x = Conv2D(filter_num[1], (3, 3), strides=1, padding='same', name=name + '_conv2')(x)\n",
    "        x = BatchNormalization(axis=3, name=name + '_bn2')(x)\n",
    "        x = Activation('relu', name=name + '_relu2')(x)\n",
    "\n",
    "        x = Conv2D(filter_num[2], (1, 1), strides=1, padding='same', name=name + '_conv3')(x)\n",
    "        x = BatchNormalization(axis=3, name=name + '_bn3')(x)\n",
    "        if atten:\n",
    "            # Channel Attention\n",
    "            avgpool = GlobalAveragePooling2D(name=name + '_channel_avgpool')(x)\n",
    "            maxpool = GlobalMaxPool2D(name=name + '_channel_maxpool')(x)\n",
    "            # Shared MLP\n",
    "            Dense_layer1 = Dense(filter_num[2] // reduction_ratio, activation='relu', name=name + '_channel_fc1')\n",
    "            Dense_layer2 = Dense(filter_num[2], activation='relu', name=name + '_channel_fc2')\n",
    "            avg_out = Dense_layer2(Dense_layer1(avgpool))\n",
    "            max_out = Dense_layer2(Dense_layer1(maxpool))\n",
    "\n",
    "            channel = add([avg_out, max_out])\n",
    "            channel = Activation('sigmoid', name=name + '_channel_sigmoid')(channel)\n",
    "            channel = Reshape((1, 1, filter_num[2]), name=name + '_channel_reshape')(channel)\n",
    "            channel_out = tf.multiply(x, channel)\n",
    "\n",
    "            # Spatial Attention\n",
    "            avgpool = tf.reduce_mean(channel_out, axis=3, keepdims=True, name=name + '_spatial_avgpool')\n",
    "            maxpool = tf.reduce_max(channel_out, axis=3, keepdims=True, name=name + '_spatial_maxpool')\n",
    "            spatial = Concatenate(axis=3)([avgpool, maxpool])\n",
    "\n",
    "            spatial = Conv2D(1, (7, 7), strides=1, padding='same', name=name + '_spatial_conv2d')(spatial)\n",
    "            spatial_out = Activation('sigmoid', name=name + '_spatial_sigmoid')(spatial)\n",
    "\n",
    "            CBAM_out = tf.multiply(channel_out, spatial_out)\n",
    "\n",
    "            # residual connection\n",
    "            r = Conv2D(filter_num[2], (1, 1), strides=stride, padding='same', name=name + '_residual')(inputs)\n",
    "            x = add([CBAM_out, r])\n",
    "        else:\n",
    "            x = Activation('relu')(x)\n",
    "            X_shortcut = Conv2D(filters=filter_num[2], kernel_size=(1, 1), strides=stride, padding='valid',\n",
    "                                name=name + 'short1')(inputs)\n",
    "            X_shortcut = BatchNormalization(axis=3, name=name + 'short2')(X_shortcut)\n",
    "            x = add([x, X_shortcut])\n",
    "        x = Activation('relu', name=name + '_relu3')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_block(self, x, filter_num, blocks, reduction_ratio=16, stride=1, name=None, atten = False):\n",
    "        x = self.conv_block(x, filter_num, reduction_ratio, stride, name=name, atten = atten)\n",
    "        for i in range(1, blocks):\n",
    "            x = self.conv_block(x, filter_num, reduction_ratio, stride=1, name=name + '_block' + str(i), atten = atten)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_model2(self, Netname, nb_classes, atten = False):\n",
    "        layers_dims = [2, 2, 2, 2]\n",
    "\n",
    "        filter_block1 = [64, 64, 256]\n",
    "        filter_block2 = [128, 128, 512]\n",
    "        filter_block3 = [256, 256, 1024]\n",
    "        filter_block4 = [512, 512, 2048]\n",
    "\n",
    "        # Reduction ratio in four blocks\n",
    "        SE_reduction = [16, 16, 16, 16]\n",
    "\n",
    "        inpt = Input(shape=(32, 32, 3))\n",
    "        x  = UpSampling2D((5,5))(inpt)\n",
    "        # stem block\n",
    "        x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='stem_conv')(x)\n",
    "        x = BatchNormalization(axis=3, name='stem_bn')(x)\n",
    "        x = Activation('relu', name='stem_relu')(x)\n",
    "        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='stem_pool')(x)\n",
    "        # convolution block\n",
    "        x = self.build_block(x, filter_block1, layers_dims[0], SE_reduction[0], name='conv1', atten = atten)\n",
    "        x = self.build_block(x, filter_block2, layers_dims[1], SE_reduction[1], stride=2, name='conv2', atten = atten)\n",
    "        x = self.build_block(x, filter_block3, layers_dims[2], SE_reduction[2], stride=2, name='conv3', atten = atten)\n",
    "        x = self.build_block(x, filter_block4, layers_dims[3], SE_reduction[3], stride=2, name='conv4', atten = atten)\n",
    "        # top layer\n",
    "        x = GlobalAveragePooling2D(name='top_layer_pool')(x)\n",
    "        x = Dense(self.num_class, activation=None, name='fc')(x)\n",
    "\n",
    "        self.model = Model(inpt, x, name=Netname)\n",
    "\n",
    "\n",
    "    def fit(self, epoch = 1000, batch_size = 32, model_ = 'base'):\n",
    "        model_checkpoint1 = ModelCheckpoint('./model/' + model_ + '.h5',\n",
    "            monitor='val_loss', verbose=1, save_best_only=True)  \n",
    "        self.model.compile(optimizer = Adam(lr=8e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-9),\n",
    "                                loss = keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "                                metrics=['accuracy'])\n",
    "        self.history = self.model.fit(x=self.train_data, y=self.train_label,\n",
    "                                      validation_data=(self.test_data, self.test_label),\n",
    "                                      epochs=epoch, batch_size=batch_size, verbose=self.verbose,\n",
    "                                      callbacks=[model_checkpoint1])\n",
    "\n",
    "    def aug_fit(self, epoch = 1000, batch_size = 16, atten = False, model_ = 'base'):\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center = True,\n",
    "            featurewise_std_normalization = True,\n",
    "            zca_epsilon=1e-06,\n",
    "            rotation_range=10, #\n",
    "            width_shift_range=0.1, \n",
    "            height_shift_range=0.1, \n",
    "            brightness_range=None,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1, \n",
    "            channel_shift_range=0.1, \n",
    "            fill_mode='nearest', \n",
    "            cval=0.1,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen.fit(np.concatenate([self.train_data, self.test_data], axis=0))\n",
    "        aug_data = datagen.flow(self.train_data, self.train_label, batch_size = batch_size, shuffle = True)\n",
    "        atten_n  = '_atten' if atten else ''\n",
    "        model_checkpoint1 = ModelCheckpoint('./model/'+ model_ + atten_n + '.h5',\n",
    "            monitor='val_loss', verbose=1, save_best_only=True) \n",
    "\n",
    "        self.model.compile(optimizer = Adam(lr=8e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-9),\n",
    "                                loss = keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "                                metrics=['accuracy'])\n",
    "        self.history = self.model.fit(aug_data,\n",
    "                                      validation_data=datagen.flow(self.test_data, self.test_label),\n",
    "                                      epochs=epoch, batch_size=batch_size, verbose=self.verbose,\n",
    "                                      callbacks=[model_checkpoint1])\n",
    "\n",
    "    def acc_test(self, model_ = 'base'):\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center = True,\n",
    "            featurewise_std_normalization = True,\n",
    "            zca_epsilon=1e-06,\n",
    "            rotation_range=10, #\n",
    "            width_shift_range=0.1, \n",
    "            height_shift_range=0.1, \n",
    "            brightness_range=None,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1, \n",
    "            channel_shift_range=0.1, \n",
    "            fill_mode='nearest', \n",
    "            cval=0.1,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "            \n",
    "        datagen.fit(np.concatenate([self.train_data, self.test_data], axis=0))\n",
    "        if os.path.exists('./model/base.h5') and model_ == 'base':\n",
    "            self.model = load_model('./model/base.h5')\n",
    "            score = self.model.evaluate(self.test_data, self.test_label, verbose = 0 )\n",
    "        elif os.path.exists('./model/improved.h5') and model_ == 'improved':\n",
    "            self.model = load_model('./model/improved.h5')\n",
    "            score = self.model.evaluate(datagen.flow(self.test_data, self.test_label), verbose = 0 )\n",
    "        elif os.path.exists('./model/improved_atten.h5') and model_ == 'attention':\n",
    "            self.model = load_model('./model/improved_atten.h5')\n",
    "            score = self.model.evaluate(datagen.flow(self.test_data, self.test_label), verbose = 0 )\n",
    "        \n",
    "        print(model_ + \" model loss: %.6f - acc: %.6f\" % (score[0], score[1]))\n",
    "\n",
    "\n",
    "mycnn = cnn('./data/cifar-100-python', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycnn.data_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        2368      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 9, 9, 32)          12832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,764\n",
      "Trainable params: 93,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fucntion to create base model\n",
    "mycnn.get_base()\n",
    "mycnn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 15.4343 - accuracy: 0.0107\n",
      "Epoch 1: val_loss improved from inf to 4.62664, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 15.4032 - accuracy: 0.0107 - val_loss: 4.6266 - val_accuracy: 0.0104\n",
      "Epoch 2/50\n",
      "1551/1563 [============================>.] - ETA: 0s - loss: 4.6226 - accuracy: 0.0096\n",
      "Epoch 2: val_loss improved from 4.62664 to 4.60939, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.6226 - accuracy: 0.0096 - val_loss: 4.6094 - val_accuracy: 0.0100\n",
      "Epoch 3/50\n",
      "1550/1563 [============================>.] - ETA: 0s - loss: 4.6088 - accuracy: 0.0097\n",
      "Epoch 3: val_loss improved from 4.60939 to 4.60702, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.6089 - accuracy: 0.0097 - val_loss: 4.6070 - val_accuracy: 0.0102\n",
      "Epoch 4/50\n",
      "1551/1563 [============================>.] - ETA: 0s - loss: 4.6051 - accuracy: 0.0093\n",
      "Epoch 4: val_loss improved from 4.60702 to 4.60658, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.6052 - accuracy: 0.0092 - val_loss: 4.6066 - val_accuracy: 0.0105\n",
      "Epoch 5/50\n",
      "1551/1563 [============================>.] - ETA: 0s - loss: 4.6038 - accuracy: 0.0099\n",
      "Epoch 5: val_loss improved from 4.60658 to 4.60341, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.6038 - accuracy: 0.0099 - val_loss: 4.6034 - val_accuracy: 0.0103\n",
      "Epoch 6/50\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 4.5989 - accuracy: 0.0106\n",
      "Epoch 6: val_loss improved from 4.60341 to 4.59640, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.5989 - accuracy: 0.0106 - val_loss: 4.5964 - val_accuracy: 0.0121\n",
      "Epoch 7/50\n",
      "1556/1563 [============================>.] - ETA: 0s - loss: 4.5801 - accuracy: 0.0122\n",
      "Epoch 7: val_loss improved from 4.59640 to 4.56765, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.5803 - accuracy: 0.0122 - val_loss: 4.5677 - val_accuracy: 0.0157\n",
      "Epoch 8/50\n",
      "1550/1563 [============================>.] - ETA: 0s - loss: 4.5556 - accuracy: 0.0153\n",
      "Epoch 8: val_loss improved from 4.56765 to 4.55216, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.5556 - accuracy: 0.0153 - val_loss: 4.5522 - val_accuracy: 0.0166\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 4.5301 - accuracy: 0.0178\n",
      "Epoch 9: val_loss improved from 4.55216 to 4.52989, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.5301 - accuracy: 0.0178 - val_loss: 4.5299 - val_accuracy: 0.0170\n",
      "Epoch 10/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 4.5142 - accuracy: 0.0184\n",
      "Epoch 10: val_loss improved from 4.52989 to 4.51626, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.5142 - accuracy: 0.0184 - val_loss: 4.5163 - val_accuracy: 0.0180\n",
      "Epoch 11/50\n",
      "1549/1563 [============================>.] - ETA: 0s - loss: 4.4956 - accuracy: 0.0189\n",
      "Epoch 11: val_loss improved from 4.51626 to 4.50067, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4954 - accuracy: 0.0189 - val_loss: 4.5007 - val_accuracy: 0.0194\n",
      "Epoch 12/50\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 4.4809 - accuracy: 0.0228\n",
      "Epoch 12: val_loss did not improve from 4.50067\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4811 - accuracy: 0.0228 - val_loss: 4.5009 - val_accuracy: 0.0221\n",
      "Epoch 13/50\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 4.4576 - accuracy: 0.0260\n",
      "Epoch 13: val_loss improved from 4.50067 to 4.48191, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4577 - accuracy: 0.0260 - val_loss: 4.4819 - val_accuracy: 0.0283\n",
      "Epoch 14/50\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 4.4335 - accuracy: 0.0291\n",
      "Epoch 14: val_loss improved from 4.48191 to 4.45474, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4336 - accuracy: 0.0290 - val_loss: 4.4547 - val_accuracy: 0.0271\n",
      "Epoch 15/50\n",
      "1553/1563 [============================>.] - ETA: 0s - loss: 4.4093 - accuracy: 0.0322\n",
      "Epoch 15: val_loss improved from 4.45474 to 4.43405, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4090 - accuracy: 0.0322 - val_loss: 4.4341 - val_accuracy: 0.0316\n",
      "Epoch 16/50\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 4.3856 - accuracy: 0.0342\n",
      "Epoch 16: val_loss improved from 4.43405 to 4.40907, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.3858 - accuracy: 0.0342 - val_loss: 4.4091 - val_accuracy: 0.0329\n",
      "Epoch 17/50\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 4.3666 - accuracy: 0.0359\n",
      "Epoch 17: val_loss improved from 4.40907 to 4.39834, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.3665 - accuracy: 0.0361 - val_loss: 4.3983 - val_accuracy: 0.0372\n",
      "Epoch 18/50\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 4.3372 - accuracy: 0.0379\n",
      "Epoch 18: val_loss improved from 4.39834 to 4.35498, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.3367 - accuracy: 0.0379 - val_loss: 4.3550 - val_accuracy: 0.0425\n",
      "Epoch 19/50\n",
      "1550/1563 [============================>.] - ETA: 0s - loss: 4.3074 - accuracy: 0.0437\n",
      "Epoch 19: val_loss improved from 4.35498 to 4.33702, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.3076 - accuracy: 0.0437 - val_loss: 4.3370 - val_accuracy: 0.0446\n",
      "Epoch 20/50\n",
      "1549/1563 [============================>.] - ETA: 0s - loss: 4.2720 - accuracy: 0.0469\n",
      "Epoch 20: val_loss improved from 4.33702 to 4.32775, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.2709 - accuracy: 0.0470 - val_loss: 4.3278 - val_accuracy: 0.0497\n",
      "Epoch 21/50\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 4.2399 - accuracy: 0.0510\n",
      "Epoch 21: val_loss improved from 4.32775 to 4.28920, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.2400 - accuracy: 0.0510 - val_loss: 4.2892 - val_accuracy: 0.0489\n",
      "Epoch 22/50\n",
      "1556/1563 [============================>.] - ETA: 0s - loss: 4.2074 - accuracy: 0.0541\n",
      "Epoch 22: val_loss improved from 4.28920 to 4.28274, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.2074 - accuracy: 0.0541 - val_loss: 4.2827 - val_accuracy: 0.0562\n",
      "Epoch 23/50\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 4.1800 - accuracy: 0.0572\n",
      "Epoch 23: val_loss improved from 4.28274 to 4.25646, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.1804 - accuracy: 0.0571 - val_loss: 4.2565 - val_accuracy: 0.0580\n",
      "Epoch 24/50\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 4.1541 - accuracy: 0.0619\n",
      "Epoch 24: val_loss improved from 4.25646 to 4.24920, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.1536 - accuracy: 0.0619 - val_loss: 4.2492 - val_accuracy: 0.0594\n",
      "Epoch 25/50\n",
      "1548/1563 [============================>.] - ETA: 0s - loss: 4.1269 - accuracy: 0.0652\n",
      "Epoch 25: val_loss improved from 4.24920 to 4.21591, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.1266 - accuracy: 0.0653 - val_loss: 4.2159 - val_accuracy: 0.0633\n",
      "Epoch 26/50\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 4.0983 - accuracy: 0.0697\n",
      "Epoch 26: val_loss improved from 4.21591 to 4.19992, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0986 - accuracy: 0.0697 - val_loss: 4.1999 - val_accuracy: 0.0639\n",
      "Epoch 27/50\n",
      "1550/1563 [============================>.] - ETA: 0s - loss: 4.0735 - accuracy: 0.0741\n",
      "Epoch 27: val_loss improved from 4.19992 to 4.19387, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0742 - accuracy: 0.0741 - val_loss: 4.1939 - val_accuracy: 0.0652\n",
      "Epoch 28/50\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 4.0489 - accuracy: 0.0772\n",
      "Epoch 28: val_loss improved from 4.19387 to 4.18380, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0483 - accuracy: 0.0773 - val_loss: 4.1838 - val_accuracy: 0.0703\n",
      "Epoch 29/50\n",
      "1552/1563 [============================>.] - ETA: 0s - loss: 4.0241 - accuracy: 0.0807\n",
      "Epoch 29: val_loss improved from 4.18380 to 4.17789, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0234 - accuracy: 0.0809 - val_loss: 4.1779 - val_accuracy: 0.0667\n",
      "Epoch 30/50\n",
      "1551/1563 [============================>.] - ETA: 0s - loss: 3.9997 - accuracy: 0.0837\n",
      "Epoch 30: val_loss improved from 4.17789 to 4.16409, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.9997 - accuracy: 0.0837 - val_loss: 4.1641 - val_accuracy: 0.0725\n",
      "Epoch 31/50\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 3.9766 - accuracy: 0.0876\n",
      "Epoch 31: val_loss did not improve from 4.16409\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.9768 - accuracy: 0.0875 - val_loss: 4.1718 - val_accuracy: 0.0789\n",
      "Epoch 32/50\n",
      "1555/1563 [============================>.] - ETA: 0s - loss: 3.9541 - accuracy: 0.0908\n",
      "Epoch 32: val_loss improved from 4.16409 to 4.13786, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.9542 - accuracy: 0.0907 - val_loss: 4.1379 - val_accuracy: 0.0810\n",
      "Epoch 33/50\n",
      "1555/1563 [============================>.] - ETA: 0s - loss: 3.9318 - accuracy: 0.0949\n",
      "Epoch 33: val_loss did not improve from 4.13786\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.9318 - accuracy: 0.0949 - val_loss: 4.1491 - val_accuracy: 0.0789\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 3.9122 - accuracy: 0.0985\n",
      "Epoch 34: val_loss improved from 4.13786 to 4.12085, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.9122 - accuracy: 0.0985 - val_loss: 4.1208 - val_accuracy: 0.0851\n",
      "Epoch 35/50\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.8922 - accuracy: 0.1016\n",
      "Epoch 35: val_loss improved from 4.12085 to 4.10117, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.8923 - accuracy: 0.1016 - val_loss: 4.1012 - val_accuracy: 0.0883\n",
      "Epoch 36/50\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.8699 - accuracy: 0.1047\n",
      "Epoch 36: val_loss did not improve from 4.10117\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.8699 - accuracy: 0.1047 - val_loss: 4.1080 - val_accuracy: 0.0925\n",
      "Epoch 37/50\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 3.8483 - accuracy: 0.1096\n",
      "Epoch 37: val_loss did not improve from 4.10117\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.8487 - accuracy: 0.1096 - val_loss: 4.1407 - val_accuracy: 0.0939\n",
      "Epoch 38/50\n",
      "1552/1563 [============================>.] - ETA: 0s - loss: 3.8230 - accuracy: 0.1131\n",
      "Epoch 38: val_loss did not improve from 4.10117\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.8232 - accuracy: 0.1130 - val_loss: 4.1293 - val_accuracy: 0.0956\n",
      "Epoch 39/50\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.8027 - accuracy: 0.1174\n",
      "Epoch 39: val_loss improved from 4.10117 to 4.08236, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.8028 - accuracy: 0.1173 - val_loss: 4.0824 - val_accuracy: 0.0972\n",
      "Epoch 40/50\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 3.7798 - accuracy: 0.1193\n",
      "Epoch 40: val_loss did not improve from 4.08236\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7807 - accuracy: 0.1193 - val_loss: 4.0945 - val_accuracy: 0.1016\n",
      "Epoch 41/50\n",
      "1551/1563 [============================>.] - ETA: 0s - loss: 3.7596 - accuracy: 0.1234\n",
      "Epoch 41: val_loss did not improve from 4.08236\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7599 - accuracy: 0.1231 - val_loss: 4.0884 - val_accuracy: 0.1009\n",
      "Epoch 42/50\n",
      "1552/1563 [============================>.] - ETA: 0s - loss: 3.7365 - accuracy: 0.1258\n",
      "Epoch 42: val_loss did not improve from 4.08236\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7366 - accuracy: 0.1258 - val_loss: 4.0844 - val_accuracy: 0.1070\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 3.7162 - accuracy: 0.1308\n",
      "Epoch 43: val_loss improved from 4.08236 to 4.07408, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7162 - accuracy: 0.1308 - val_loss: 4.0741 - val_accuracy: 0.1051\n",
      "Epoch 44/50\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 3.6959 - accuracy: 0.1361\n",
      "Epoch 44: val_loss improved from 4.07408 to 4.05584, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.6956 - accuracy: 0.1362 - val_loss: 4.0558 - val_accuracy: 0.1063\n",
      "Epoch 45/50\n",
      "1553/1563 [============================>.] - ETA: 0s - loss: 3.6727 - accuracy: 0.1391\n",
      "Epoch 45: val_loss did not improve from 4.05584\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.6727 - accuracy: 0.1391 - val_loss: 4.0625 - val_accuracy: 0.1090\n",
      "Epoch 46/50\n",
      "1553/1563 [============================>.] - ETA: 0s - loss: 3.6524 - accuracy: 0.1425\n",
      "Epoch 46: val_loss did not improve from 4.05584\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6524 - accuracy: 0.1425 - val_loss: 4.0576 - val_accuracy: 0.1066\n",
      "Epoch 47/50\n",
      "1548/1563 [============================>.] - ETA: 0s - loss: 3.6327 - accuracy: 0.1465\n",
      "Epoch 47: val_loss did not improve from 4.05584\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6325 - accuracy: 0.1464 - val_loss: 4.1151 - val_accuracy: 0.1107\n",
      "Epoch 48/50\n",
      "1550/1563 [============================>.] - ETA: 0s - loss: 3.6111 - accuracy: 0.1493\n",
      "Epoch 48: val_loss did not improve from 4.05584\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.6123 - accuracy: 0.1491 - val_loss: 4.0882 - val_accuracy: 0.1142\n",
      "Epoch 49/50\n",
      "1555/1563 [============================>.] - ETA: 0s - loss: 3.5885 - accuracy: 0.1535\n",
      "Epoch 49: val_loss did not improve from 4.05584\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.5886 - accuracy: 0.1534 - val_loss: 4.0582 - val_accuracy: 0.1163\n",
      "Epoch 50/50\n",
      "1552/1563 [============================>.] - ETA: 0s - loss: 3.5683 - accuracy: 0.1574\n",
      "Epoch 50: val_loss did not improve from 4.05584\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.5678 - accuracy: 0.1574 - val_loss: 4.0994 - val_accuracy: 0.1177\n"
     ]
    }
   ],
   "source": [
    "mycnn.fit(epoch = 20, batch_size =32, model_= 'base') #epoch is 50 in the report but reduce to 20 when submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycnn.acc_test('base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aug and attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 4.3969 - accuracy: 0.0443\n",
      "Epoch 1: val_loss improved from inf to 4.16623, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 31s 19ms/step - loss: 4.3967 - accuracy: 0.0443 - val_loss: 4.1662 - val_accuracy: 0.0682\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 4.0544 - accuracy: 0.0881\n",
      "Epoch 2: val_loss improved from 4.16623 to 3.96820, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 4.0544 - accuracy: 0.0881 - val_loss: 3.9682 - val_accuracy: 0.0967\n",
      "Epoch 3/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.8972 - accuracy: 0.1089\n",
      "Epoch 3: val_loss improved from 3.96820 to 3.85345, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 3.8972 - accuracy: 0.1089 - val_loss: 3.8535 - val_accuracy: 0.1163\n",
      "Epoch 4/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.7870 - accuracy: 0.1258\n",
      "Epoch 4: val_loss improved from 3.85345 to 3.77100, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 3.7867 - accuracy: 0.1258 - val_loss: 3.7710 - val_accuracy: 0.1312\n",
      "Epoch 5/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.6994 - accuracy: 0.1401\n",
      "Epoch 5: val_loss improved from 3.77100 to 3.68100, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 3.6993 - accuracy: 0.1403 - val_loss: 3.6810 - val_accuracy: 0.1419\n",
      "Epoch 6/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 3.6306 - accuracy: 0.1516\n",
      "Epoch 6: val_loss improved from 3.68100 to 3.64184, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 3.6305 - accuracy: 0.1516 - val_loss: 3.6418 - val_accuracy: 0.1557\n",
      "Epoch 7/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 3.5603 - accuracy: 0.1631\n",
      "Epoch 7: val_loss improved from 3.64184 to 3.56250, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 3.5604 - accuracy: 0.1631 - val_loss: 3.5625 - val_accuracy: 0.1634\n",
      "Epoch 8/20\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 3.5058 - accuracy: 0.1724\n",
      "Epoch 8: val_loss improved from 3.56250 to 3.51733, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 3.5058 - accuracy: 0.1724 - val_loss: 3.5173 - val_accuracy: 0.1704\n",
      "Epoch 9/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.4633 - accuracy: 0.1782\n",
      "Epoch 9: val_loss improved from 3.51733 to 3.48579, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 3.4629 - accuracy: 0.1784 - val_loss: 3.4858 - val_accuracy: 0.1747\n",
      "Epoch 10/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 3.4149 - accuracy: 0.1871\n",
      "Epoch 10: val_loss improved from 3.48579 to 3.43903, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 3.4148 - accuracy: 0.1871 - val_loss: 3.4390 - val_accuracy: 0.1893\n",
      "Epoch 11/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 3.3710 - accuracy: 0.1941\n",
      "Epoch 11: val_loss improved from 3.43903 to 3.39633, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 3.3709 - accuracy: 0.1941 - val_loss: 3.3963 - val_accuracy: 0.1950\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 3.3327 - accuracy: 0.2011\n",
      "Epoch 12: val_loss improved from 3.39633 to 3.37925, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 3.3327 - accuracy: 0.2011 - val_loss: 3.3792 - val_accuracy: 0.1943\n",
      "Epoch 13/20\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 3.2975 - accuracy: 0.2053\n",
      "Epoch 13: val_loss improved from 3.37925 to 3.34068, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 3.2979 - accuracy: 0.2053 - val_loss: 3.3407 - val_accuracy: 0.1986\n",
      "Epoch 14/20\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 3.2729 - accuracy: 0.2128\n",
      "Epoch 14: val_loss improved from 3.34068 to 3.28866, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 3.2727 - accuracy: 0.2129 - val_loss: 3.2887 - val_accuracy: 0.2142\n",
      "Epoch 15/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.2407 - accuracy: 0.2167\n",
      "Epoch 15: val_loss improved from 3.28866 to 3.27329, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 3.2407 - accuracy: 0.2167 - val_loss: 3.2733 - val_accuracy: 0.2201\n",
      "Epoch 16/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.2191 - accuracy: 0.2225\n",
      "Epoch 16: val_loss improved from 3.27329 to 3.26060, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 3.2188 - accuracy: 0.2225 - val_loss: 3.2606 - val_accuracy: 0.2183\n",
      "Epoch 17/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.1961 - accuracy: 0.2246\n",
      "Epoch 17: val_loss improved from 3.26060 to 3.23729, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 3.1959 - accuracy: 0.2246 - val_loss: 3.2373 - val_accuracy: 0.2191\n",
      "Epoch 18/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.1712 - accuracy: 0.2316\n",
      "Epoch 18: val_loss improved from 3.23729 to 3.20807, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 3.1708 - accuracy: 0.2316 - val_loss: 3.2081 - val_accuracy: 0.2291\n",
      "Epoch 19/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 3.1484 - accuracy: 0.2328\n",
      "Epoch 19: val_loss improved from 3.20807 to 3.18061, saving model to ./model\\base.h5\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 3.1482 - accuracy: 0.2329 - val_loss: 3.1806 - val_accuracy: 0.2347\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 3.1299 - accuracy: 0.2366\n",
      "Epoch 20: val_loss did not improve from 3.18061\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 3.1299 - accuracy: 0.2366 - val_loss: 3.1850 - val_accuracy: 0.2291\n"
     ]
    }
   ],
   "source": [
    "#fucntion to create imroved model, if the atten is True, the model will add attention approach\n",
    "mycnn.get_base()\n",
    "mycnn.aug_fit(epoch = 20, batch_size = 32, model_= 'improved') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 3.5227 - accuracy: 0.1698\n",
      "Epoch 1: val_loss improved from inf to 3.16425, saving model to ./model\\improved.h5\n",
      "1563/1563 [==============================] - 102s 64ms/step - loss: 3.5228 - accuracy: 0.1698 - val_loss: 3.1642 - val_accuracy: 0.2286\n",
      "Epoch 2/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 2.7211 - accuracy: 0.3123\n",
      "Epoch 2: val_loss improved from 3.16425 to 3.04120, saving model to ./model\\improved.h5\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 2.7212 - accuracy: 0.3124 - val_loss: 3.0412 - val_accuracy: 0.2686\n",
      "Epoch 3/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 2.2158 - accuracy: 0.4185\n",
      "Epoch 3: val_loss improved from 3.04120 to 2.57776, saving model to ./model\\improved.h5\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 2.2156 - accuracy: 0.4186 - val_loss: 2.5778 - val_accuracy: 0.3431\n",
      "Epoch 4/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.8132 - accuracy: 0.5102\n",
      "Epoch 4: val_loss improved from 2.57776 to 2.46524, saving model to ./model\\improved.h5\n",
      "1563/1563 [==============================] - 104s 66ms/step - loss: 1.8130 - accuracy: 0.5102 - val_loss: 2.4652 - val_accuracy: 0.3783\n",
      "Epoch 5/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.4324 - accuracy: 0.6020\n",
      "Epoch 5: val_loss improved from 2.46524 to 2.24567, saving model to ./model\\improved.h5\n",
      "1563/1563 [==============================] - 101s 65ms/step - loss: 1.4323 - accuracy: 0.6020 - val_loss: 2.2457 - val_accuracy: 0.4276\n",
      "Epoch 6/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.0661 - accuracy: 0.6985\n",
      "Epoch 6: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 101s 65ms/step - loss: 1.0661 - accuracy: 0.6984 - val_loss: 2.5566 - val_accuracy: 0.3903\n",
      "Epoch 7/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7309 - accuracy: 0.7938\n",
      "Epoch 7: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.7310 - accuracy: 0.7938 - val_loss: 2.6040 - val_accuracy: 0.4076\n",
      "Epoch 8/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4763 - accuracy: 0.8675\n",
      "Epoch 8: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.4764 - accuracy: 0.8675 - val_loss: 3.3103 - val_accuracy: 0.3465\n",
      "Epoch 9/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.9060\n",
      "Epoch 9: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.3389 - accuracy: 0.9060 - val_loss: 2.9496 - val_accuracy: 0.3887\n",
      "Epoch 10/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2629 - accuracy: 0.9259\n",
      "Epoch 10: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.2629 - accuracy: 0.9259 - val_loss: 4.1583 - val_accuracy: 0.3065\n",
      "Epoch 11/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9340\n",
      "Epoch 11: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.2286 - accuracy: 0.9339 - val_loss: 3.4901 - val_accuracy: 0.3802\n",
      "Epoch 12/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1920 - accuracy: 0.9447\n",
      "Epoch 12: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.1920 - accuracy: 0.9447 - val_loss: 3.4459 - val_accuracy: 0.3663\n",
      "Epoch 13/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9512\n",
      "Epoch 13: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.1720 - accuracy: 0.9511 - val_loss: 3.4235 - val_accuracy: 0.3896\n",
      "Epoch 14/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9496\n",
      "Epoch 14: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.1702 - accuracy: 0.9496 - val_loss: 3.8711 - val_accuracy: 0.3912\n",
      "Epoch 15/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9568\n",
      "Epoch 15: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 101s 64ms/step - loss: 0.1458 - accuracy: 0.9568 - val_loss: 3.7040 - val_accuracy: 0.3873\n",
      "Epoch 16/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9584\n",
      "Epoch 16: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 104s 67ms/step - loss: 0.1401 - accuracy: 0.9583 - val_loss: 3.6747 - val_accuracy: 0.4031\n",
      "Epoch 17/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1343 - accuracy: 0.9608\n",
      "Epoch 17: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 107s 68ms/step - loss: 0.1344 - accuracy: 0.9608 - val_loss: 3.9331 - val_accuracy: 0.3952\n",
      "Epoch 18/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1212 - accuracy: 0.9640\n",
      "Epoch 18: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 106s 68ms/step - loss: 0.1212 - accuracy: 0.9640 - val_loss: 3.8475 - val_accuracy: 0.3847\n",
      "Epoch 19/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.9653\n",
      "Epoch 19: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 106s 68ms/step - loss: 0.1152 - accuracy: 0.9653 - val_loss: 3.5595 - val_accuracy: 0.4204\n",
      "Epoch 20/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9667\n",
      "Epoch 20: val_loss did not improve from 2.24567\n",
      "1563/1563 [==============================] - 106s 68ms/step - loss: 0.1134 - accuracy: 0.9667 - val_loss: 3.5364 - val_accuracy: 0.4115\n"
     ]
    }
   ],
   "source": [
    "mycnn.get_model2('ResNet', 100)\n",
    "mycnn.fit(epoch = 5, model_= 'improved') #epoch is 20 in the report but reduce to 5 when submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 3.7976 - accuracy: 0.1240\n",
      "Epoch 1: val_loss improved from inf to 3.57285, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 126s 39ms/step - loss: 3.7975 - accuracy: 0.1240 - val_loss: 3.5728 - val_accuracy: 0.1685\n",
      "Epoch 2/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 3.1901 - accuracy: 0.2192\n",
      "Epoch 2: val_loss improved from 3.57285 to 3.01279, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 121s 39ms/step - loss: 3.1901 - accuracy: 0.2192 - val_loss: 3.0128 - val_accuracy: 0.2534\n",
      "Epoch 3/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.8253 - accuracy: 0.2912\n",
      "Epoch 3: val_loss improved from 3.01279 to 2.75338, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 121s 39ms/step - loss: 2.8253 - accuracy: 0.2912 - val_loss: 2.7534 - val_accuracy: 0.2997\n",
      "Epoch 4/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.5645 - accuracy: 0.3410\n",
      "Epoch 4: val_loss improved from 2.75338 to 2.42612, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 129s 41ms/step - loss: 2.5645 - accuracy: 0.3410 - val_loss: 2.4261 - val_accuracy: 0.3633\n",
      "Epoch 5/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.3746 - accuracy: 0.3808\n",
      "Epoch 5: val_loss did not improve from 2.42612\n",
      "3125/3125 [==============================] - 122s 39ms/step - loss: 2.3746 - accuracy: 0.3808 - val_loss: 2.4838 - val_accuracy: 0.3732\n",
      "Epoch 6/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.2034 - accuracy: 0.4189\n",
      "Epoch 6: val_loss improved from 2.42612 to 2.34053, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 121s 39ms/step - loss: 2.2034 - accuracy: 0.4189 - val_loss: 2.3405 - val_accuracy: 0.3864\n",
      "Epoch 7/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.0843 - accuracy: 0.4422\n",
      "Epoch 7: val_loss improved from 2.34053 to 2.09536, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 121s 39ms/step - loss: 2.0843 - accuracy: 0.4422 - val_loss: 2.0954 - val_accuracy: 0.4495\n",
      "Epoch 8/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.9736 - accuracy: 0.4680\n",
      "Epoch 8: val_loss did not improve from 2.09536\n",
      "3125/3125 [==============================] - 124s 40ms/step - loss: 1.9736 - accuracy: 0.4680 - val_loss: 2.1596 - val_accuracy: 0.4408\n",
      "Epoch 9/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.8775 - accuracy: 0.4894\n",
      "Epoch 9: val_loss improved from 2.09536 to 1.92074, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 124s 40ms/step - loss: 1.8775 - accuracy: 0.4894 - val_loss: 1.9207 - val_accuracy: 0.4843\n",
      "Epoch 10/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.7782 - accuracy: 0.5136\n",
      "Epoch 10: val_loss did not improve from 1.92074\n",
      "3125/3125 [==============================] - 125s 40ms/step - loss: 1.7782 - accuracy: 0.5136 - val_loss: 1.9700 - val_accuracy: 0.4795\n",
      "Epoch 11/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.7148 - accuracy: 0.5265\n",
      "Epoch 11: val_loss did not improve from 1.92074\n",
      "3125/3125 [==============================] - 127s 41ms/step - loss: 1.7148 - accuracy: 0.5265 - val_loss: 2.0062 - val_accuracy: 0.4755\n",
      "Epoch 12/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.6406 - accuracy: 0.5458\n",
      "Epoch 12: val_loss improved from 1.92074 to 1.78910, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 129s 41ms/step - loss: 1.6406 - accuracy: 0.5458 - val_loss: 1.7891 - val_accuracy: 0.5155\n",
      "Epoch 13/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.5787 - accuracy: 0.5598\n",
      "Epoch 13: val_loss did not improve from 1.78910\n",
      "3125/3125 [==============================] - 131s 42ms/step - loss: 1.5787 - accuracy: 0.5598 - val_loss: 1.7895 - val_accuracy: 0.5172\n",
      "Epoch 14/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.5156 - accuracy: 0.5758\n",
      "Epoch 14: val_loss improved from 1.78910 to 1.60772, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 129s 41ms/step - loss: 1.5156 - accuracy: 0.5758 - val_loss: 1.6077 - val_accuracy: 0.5532\n",
      "Epoch 15/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.5878\n",
      "Epoch 15: val_loss did not improve from 1.60772\n",
      "3125/3125 [==============================] - 124s 40ms/step - loss: 1.4639 - accuracy: 0.5878 - val_loss: 1.6253 - val_accuracy: 0.5605\n",
      "Epoch 16/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.4083 - accuracy: 0.6028\n",
      "Epoch 16: val_loss did not improve from 1.60772\n",
      "3125/3125 [==============================] - 127s 41ms/step - loss: 1.4083 - accuracy: 0.6028 - val_loss: 1.6676 - val_accuracy: 0.5492\n",
      "Epoch 17/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.3648 - accuracy: 0.6104\n",
      "Epoch 17: val_loss did not improve from 1.60772\n",
      "3125/3125 [==============================] - 130s 42ms/step - loss: 1.3648 - accuracy: 0.6104 - val_loss: 1.6239 - val_accuracy: 0.5657\n",
      "Epoch 18/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.3223 - accuracy: 0.6234\n",
      "Epoch 18: val_loss did not improve from 1.60772\n",
      "3125/3125 [==============================] - 126s 40ms/step - loss: 1.3223 - accuracy: 0.6234 - val_loss: 1.9041 - val_accuracy: 0.5135\n",
      "Epoch 19/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.2829 - accuracy: 0.6326\n",
      "Epoch 19: val_loss improved from 1.60772 to 1.52334, saving model to ./model\\improved.h5\n",
      "3125/3125 [==============================] - 124s 40ms/step - loss: 1.2829 - accuracy: 0.6326 - val_loss: 1.5233 - val_accuracy: 0.5845\n",
      "Epoch 20/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.2342 - accuracy: 0.6459\n",
      "Epoch 20: val_loss did not improve from 1.52334\n",
      "3125/3125 [==============================] - 124s 40ms/step - loss: 1.2342 - accuracy: 0.6459 - val_loss: 1.5299 - val_accuracy: 0.5808\n"
     ]
    }
   ],
   "source": [
    "mycnn.get_model2('ResNet', 100)\n",
    "mycnn.aug_fit(epoch = 5, model_= 'improved') #epoch is 20 in the report but reduce to 5 when submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improved model loss: 1.531700 - acc: 0.580800\n"
     ]
    }
   ],
   "source": [
    "mycnn.acc_test('improved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 3.7906 - accuracy: 0.1168\n",
      "Epoch 1: val_loss improved from inf to 3.40376, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 193s 60ms/step - loss: 3.7906 - accuracy: 0.1168 - val_loss: 3.4038 - val_accuracy: 0.1781\n",
      "Epoch 2/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 3.2003 - accuracy: 0.2107\n",
      "Epoch 2: val_loss improved from 3.40376 to 2.93828, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 182s 58ms/step - loss: 3.2003 - accuracy: 0.2107 - val_loss: 2.9383 - val_accuracy: 0.2633\n",
      "Epoch 3/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.8466 - accuracy: 0.2785\n",
      "Epoch 3: val_loss improved from 2.93828 to 2.64393, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 192s 61ms/step - loss: 2.8466 - accuracy: 0.2785 - val_loss: 2.6439 - val_accuracy: 0.3227\n",
      "Epoch 4/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.5846 - accuracy: 0.3347\n",
      "Epoch 4: val_loss improved from 2.64393 to 2.58714, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 193s 62ms/step - loss: 2.5846 - accuracy: 0.3347 - val_loss: 2.5871 - val_accuracy: 0.3345\n",
      "Epoch 5/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.3842 - accuracy: 0.3734\n",
      "Epoch 5: val_loss improved from 2.58714 to 2.29761, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 192s 61ms/step - loss: 2.3842 - accuracy: 0.3734 - val_loss: 2.2976 - val_accuracy: 0.3953\n",
      "Epoch 6/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.2080 - accuracy: 0.4144\n",
      "Epoch 6: val_loss did not improve from 2.29761\n",
      "3125/3125 [==============================] - 192s 61ms/step - loss: 2.2080 - accuracy: 0.4144 - val_loss: 2.4028 - val_accuracy: 0.3780\n",
      "Epoch 7/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.0661 - accuracy: 0.4414\n",
      "Epoch 7: val_loss improved from 2.29761 to 2.10181, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 192s 61ms/step - loss: 2.0661 - accuracy: 0.4414 - val_loss: 2.1018 - val_accuracy: 0.4480\n",
      "Epoch 8/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.9364 - accuracy: 0.4712\n",
      "Epoch 8: val_loss improved from 2.10181 to 2.09364, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 194s 62ms/step - loss: 1.9364 - accuracy: 0.4712 - val_loss: 2.0936 - val_accuracy: 0.4480\n",
      "Epoch 9/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.8240 - accuracy: 0.4987\n",
      "Epoch 9: val_loss improved from 2.09364 to 1.83488, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 191s 61ms/step - loss: 1.8240 - accuracy: 0.4987 - val_loss: 1.8349 - val_accuracy: 0.4976\n",
      "Epoch 10/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.7264 - accuracy: 0.5235\n",
      "Epoch 10: val_loss did not improve from 1.83488\n",
      "3125/3125 [==============================] - 193s 62ms/step - loss: 1.7264 - accuracy: 0.5235 - val_loss: 1.8604 - val_accuracy: 0.4980\n",
      "Epoch 11/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.6301 - accuracy: 0.5459\n",
      "Epoch 11: val_loss improved from 1.83488 to 1.75889, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 191s 61ms/step - loss: 1.6301 - accuracy: 0.5459 - val_loss: 1.7589 - val_accuracy: 0.5186\n",
      "Epoch 12/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.5559 - accuracy: 0.5617\n",
      "Epoch 12: val_loss improved from 1.75889 to 1.71114, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 1.5559 - accuracy: 0.5617 - val_loss: 1.7111 - val_accuracy: 0.5370\n",
      "Epoch 13/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.4804 - accuracy: 0.5825\n",
      "Epoch 13: val_loss did not improve from 1.71114\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 1.4804 - accuracy: 0.5825 - val_loss: 1.7301 - val_accuracy: 0.5252\n",
      "Epoch 14/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.4147 - accuracy: 0.5985\n",
      "Epoch 14: val_loss improved from 1.71114 to 1.62692, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 187s 60ms/step - loss: 1.4147 - accuracy: 0.5985 - val_loss: 1.6269 - val_accuracy: 0.5489\n",
      "Epoch 15/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.3470 - accuracy: 0.6154\n",
      "Epoch 15: val_loss did not improve from 1.62692\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 1.3470 - accuracy: 0.6154 - val_loss: 1.6366 - val_accuracy: 0.5513\n",
      "Epoch 16/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.2908 - accuracy: 0.6280\n",
      "Epoch 16: val_loss improved from 1.62692 to 1.57861, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 192s 61ms/step - loss: 1.2908 - accuracy: 0.6280 - val_loss: 1.5786 - val_accuracy: 0.5654\n",
      "Epoch 17/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.2306 - accuracy: 0.6426\n",
      "Epoch 17: val_loss did not improve from 1.57861\n",
      "3125/3125 [==============================] - 184s 59ms/step - loss: 1.2306 - accuracy: 0.6426 - val_loss: 1.6044 - val_accuracy: 0.5617\n",
      "Epoch 18/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.1801 - accuracy: 0.6542\n",
      "Epoch 18: val_loss improved from 1.57861 to 1.51625, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 190s 61ms/step - loss: 1.1801 - accuracy: 0.6542 - val_loss: 1.5163 - val_accuracy: 0.5831\n",
      "Epoch 19/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.1270 - accuracy: 0.6686\n",
      "Epoch 19: val_loss improved from 1.51625 to 1.49078, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 192s 61ms/step - loss: 1.1270 - accuracy: 0.6686 - val_loss: 1.4908 - val_accuracy: 0.5898\n",
      "Epoch 20/20\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.0784 - accuracy: 0.6840\n",
      "Epoch 20: val_loss improved from 1.49078 to 1.45388, saving model to ./model\\improved_atten.h5\n",
      "3125/3125 [==============================] - 189s 60ms/step - loss: 1.0784 - accuracy: 0.6840 - val_loss: 1.4539 - val_accuracy: 0.5977\n"
     ]
    }
   ],
   "source": [
    "atten = True\n",
    "mycnn.get_model2('ResNet', 100, atten)\n",
    "mycnn.aug_fit(epoch = 5,atten= atten, model_= 'improved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention model loss: 1.456160 - acc: 0.598900\n"
     ]
    }
   ],
   "source": [
    "mycnn.acc_test('attention')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
