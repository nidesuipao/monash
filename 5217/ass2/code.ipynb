{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requirements\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 150\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './Cooking_Dataset/train'\n",
    "test_path = './Cooking_Dataset/test'\n",
    "dev_path = './Cooking_Dataset/dev'\n",
    "\n",
    "train_ingradients = []\n",
    "train_recipes = []\n",
    "test_ingradients = []\n",
    "test_recipes = []\n",
    "dev_ingradients = []\n",
    "dev_recipes = []\n",
    "\n",
    "\n",
    "def data_extract(data_path):\n",
    "    ingradients = []\n",
    "    recipes = []\n",
    "    files =  os.listdir(data_path)\n",
    "    for f in files:\n",
    "        data = open(os.path.join(data_path, f))\n",
    "        lines = data.readlines()\n",
    "        is_recipe =  0\n",
    "        recipe = \"\"\n",
    "        for line in lines:\n",
    "            if \"ingredients:\" in line:\n",
    "                ingradients.append(line)\n",
    "                is_recipe = 1\n",
    "            elif 'END RECIPE' in line:\n",
    "                is_recipe = 0\n",
    "                recipes.append(recipe)\n",
    "                recipe = \"\"\n",
    "            elif is_recipe == 1:\n",
    "                line = line.replace('\\n','\\t')\n",
    "                recipe = recipe + line.replace('\\t',' ')\n",
    "           \n",
    "\n",
    "    return ingradients, recipes\n",
    "\n",
    "train_ingradients, train_recipes = data_extract(train_path)\n",
    "test_ingradients, test_recipes = data_extract(test_path)\n",
    "dev_ingradients, dev_recipes = data_extract(dev_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = input_lang = Lang(\"ing\")\n",
    "\n",
    "pairs = [[train_ingradients[i], train_recipes[i]] for i in range(len(train_ingradients))]\n",
    "pairs_test = [[test_ingradients[i], test_recipes[i]] for i in range(len(test_ingradients))]\n",
    "pairs_dev = [[dev_ingradients[i], dev_recipes[i]] for i in range(len(dev_ingradients))]\n",
    "\n",
    "\n",
    "min_train_ing_len = min([len(pair[0]) for pair in pairs])\n",
    "min_train_rec_len = min([len(pair[1]) for pair in pairs])\n",
    "\n",
    "max_train_ing_len = max([len(pair[0]) for pair in pairs])\n",
    "max_train_rec_len = max([len(pair[1]) for pair in pairs])\n",
    "\n",
    "ave_train_ing_len = sum([len(pair[0]) for pair in pairs]) / len(pairs)\n",
    "ave_train_rec_len = sum([len(pair[1]) for pair in pairs]) / len(pairs)\n",
    "\n",
    "pairs = filterPairs(pairs)\n",
    "pairs_test = filterPairs(pairs_test)\n",
    "pairs_dev = filterPairs(pairs_dev)\n",
    "\n",
    "for pair in pairs:\n",
    "        lang.addSentence(pair[0])\n",
    "        lang.addSentence(pair[1])\n",
    "\n",
    "for pair in pairs_test:\n",
    "        lang.addSentence(pair[0])\n",
    "        lang.addSentence(pair[1])\n",
    "\n",
    "for pair in pairs_dev:\n",
    "        lang.addSentence(pair[0])\n",
    "        lang.addSentence(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143907\n",
      "17 0\n",
      "2460 4427\n",
      "235.31318142967334 529.653950120564\n",
      "113100\n",
      "172249\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ingradients))\n",
    "print(min_train_ing_len, min_train_rec_len)\n",
    "print(max_train_ing_len, max_train_rec_len)\n",
    "print(ave_train_ing_len, ave_train_rec_len)\n",
    "print(len(pairs))\n",
    "print(lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(lang, pair):\n",
    "    input_tensor = tensorFromSentence(lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55, 1])\n",
      "torch.Size([110, 1])\n"
     ]
    }
   ],
   "source": [
    "x = random.choice(pairs)\n",
    "training_pairs = tensorsFromPair(lang, x)\n",
    "print(training_pairs[0].size())\n",
    "print(training_pairs[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model without attetion define and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, hidden, cell):      \n",
    "        embedded = self.embedding(src).view(1, 1, -1)  \n",
    "        embedded = self.dropout(embedded)      \n",
    "        outputs, (hidden, cell) = self.rnn(embedded, (hidden, cell))      \n",
    "        return outputs, hidden, cell\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hid_dim, device=device),torch.zeros(1, 1, self.hid_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim) \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)  \n",
    "        embedded = self.dropout(embedded)         \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        prediction = self.softmax(prediction)\n",
    "        \n",
    "        return prediction, hidden, cell\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hid_dim, device=device),torch.zeros(1, 1, self.hid_dim, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden, encoder_cell = encoder.initHidden()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hid_dim, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden, encoder_cell = encoder(\n",
    "            input_tensor[ei], encoder_hidden, encoder_cell)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_cell = encoder_cell\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "\n",
    "    return loss\n",
    "\n",
    "    #return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "    \n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01, batch_size = 10):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(lang, random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    dev_pairs = [tensorsFromPair(lang, pair) for pair in pairs_dev]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    loss = 0\n",
    "    for iter in range(1, n_iters+1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        cur_loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, criterion)\n",
    "        loss += cur_loss\n",
    "\n",
    "\n",
    "        print_loss_total += cur_loss.item() / target_tensor.size(0)\n",
    "        plot_loss_total += cur_loss.item() / target_tensor.size(0)\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            dev_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for dev_pair in dev_pairs:\n",
    "                    input_tensor = dev_pair[0]\n",
    "                    target_tensor = dev_pair[1]\n",
    "                    dev_loss += train(input_tensor, target_tensor, encoder,\n",
    "                        decoder, criterion) / target_tensor.size(0)\n",
    "            dev_loss = dev_loss.item() / len(dev_pairs)\n",
    "\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) train: %.4f dev: %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg, dev_loss))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            dev_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for dev_pair in dev_pairs:\n",
    "                    input_tensor = dev_pair[0]\n",
    "                    target_tensor = dev_pair[1]\n",
    "                    dev_loss += train(input_tensor, target_tensor, encoder,\n",
    "                        decoder, criterion) / target_tensor.size(0)\n",
    "            dev_loss = dev_loss.item() / len(dev_pairs)\n",
    "            \n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append([plot_loss_avg, dev_loss])\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "        if iter % batch_size:\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            loss = 0\n",
    "\n",
    "    # showPlot(plot_losses)\n",
    "    return plot_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = lang.n_words\n",
    "output_dim = lang.n_words\n",
    "emb_dim = 64\n",
    "hid_dim = 256\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "encoder1 = EncoderLSTM(input_dim, emb_dim, hid_dim, n_layers, dropout).to(device)\n",
    "decoder1 = DecoderLSTM(output_dim, emb_dim, hid_dim, n_layers, dropout).to(device)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder1 = torch.load('encoder1.pt')\n",
    "# decoder1 = torch.load('decoder1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 11s (- 177m 44s) (100 0%) train: 9.6214 dev: 7.4518\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\研究生资料\\研一小学期\\5217\\ass2\\code_32749112.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_process \u001b[39m=\u001b[39m trainIters(encoder1, decoder1, \u001b[39m15000\u001b[39;49m, print_every\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m batch_size)\n",
      "\u001b[1;32me:\\研究生资料\\研一小学期\\5217\\ass2\\code_32749112.ipynb Cell 19\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate, batch_size)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         input_tensor \u001b[39m=\u001b[39m dev_pair[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         target_tensor \u001b[39m=\u001b[39m dev_pair[\u001b[39m1\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         dev_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train(input_tensor, target_tensor, encoder,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m             decoder, criterion) \u001b[39m/\u001b[39m target_tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m dev_loss \u001b[39m=\u001b[39m dev_loss\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dev_pairs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m plot_loss_avg \u001b[39m=\u001b[39m plot_loss_total \u001b[39m/\u001b[39m plot_every\n",
      "\u001b[1;32me:\\研究生资料\\研一小学期\\5217\\ass2\\code_32749112.ipynb Cell 19\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, criterion, max_length)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m use_teacher_forcing:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# Teacher forcing: Feed the target as the next input\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mfor\u001b[39;00m di \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(target_length):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         decoder_output, decoder_hidden, decoder_cell \u001b[39m=\u001b[39m decoder(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m             decoder_input, decoder_hidden, decoder_cell)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion(decoder_output, target_tensor[di])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         decoder_input \u001b[39m=\u001b[39m target_tensor[di]  \u001b[39m# Teacher forcing\u001b[39;00m\n",
      "File \u001b[1;32mF:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32me:\\研究生资料\\研一小学期\\5217\\ass2\\code_32749112.ipynb Cell 19\u001b[0m in \u001b[0;36mDecoderLSTM.forward\u001b[1;34m(self, input, hidden, cell)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, hidden, cell):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(\u001b[39minput\u001b[39m)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(embedded)         \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     output, (hidden, cell) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(embedded, (hidden, cell))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%B5%84%E6%96%99/%E7%A0%94%E4%B8%80%E5%B0%8F%E5%AD%A6%E6%9C%9F/5217/ass2/code_32749112.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_out(output\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mF:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mF:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mF:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[0;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[1;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_process = trainIters(encoder1, decoder1, 15000, print_every=100, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder1,'encoder1.pt')\n",
    "torch.save(decoder1,'decoder1.pt')\n",
    "\n",
    "f = open(\"train_process.txt\", 'w+')\n",
    "for p in train_process:\n",
    "    f.write(str(p[0])+ ' ' + str(p[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden, encoder_cell = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hid_dim, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden, encoder_cell)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=2):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs_test)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words= evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model with attetion define and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderLSTM(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderLSTM, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim) \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout, batch_first=True)\n",
    "        self.attn = nn.Linear(self.hid_dim * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hid_dim * 2, self.hid_dim)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)  \n",
    "        embedded = self.dropout(embedded)  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        prediction = self.softmax(prediction)\n",
    "        \n",
    "        return prediction, hidden, cell, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hid_dim, device=device),torch.zeros(1, 1, self.hid_dim, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "\n",
    "\n",
    "def train_attn(input_tensor, target_tensor, encoder, decoder, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden, encoder_cell = encoder.initHidden()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hid_dim, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden, encoder_cell = encoder(\n",
    "            input_tensor[ei], encoder_hidden, encoder_cell)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_cell = encoder_cell\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters_attn(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01, batch_size = 10):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(lang, random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    \n",
    "    dev_pairs = [tensorsFromPair(lang, pair) for pair in pairs_dev]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    loss = 0\n",
    "    for iter in range(1, n_iters+1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        cur_loss = train_attn(input_tensor, target_tensor, encoder,\n",
    "                     decoder, criterion)\n",
    "        loss += cur_loss\n",
    "\n",
    "\n",
    "        print_loss_total += cur_loss.item() / target_tensor.size(0)\n",
    "        plot_loss_total += cur_loss.item() / target_tensor.size(0)\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            dev_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for dev_pair in dev_pairs:\n",
    "                    input_tensor = dev_pair[0]\n",
    "                    target_tensor = dev_pair[1]\n",
    "                    dev_loss += train_attn(input_tensor, target_tensor, encoder,\n",
    "                        decoder, criterion) / target_tensor.size(0)\n",
    "            dev_loss = dev_loss.item() / len(dev_pairs)\n",
    "\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) train: %.4f dev: %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg, dev_loss))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            dev_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for dev_pair in dev_pairs:\n",
    "                    input_tensor = dev_pair[0]\n",
    "                    target_tensor = dev_pair[1]\n",
    "                    dev_loss += train_attn(input_tensor, target_tensor, encoder,\n",
    "                        decoder, criterion) / target_tensor.size(0)\n",
    "            dev_loss = dev_loss.item() / len(dev_pairs)\n",
    "\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append([plot_loss_avg, dev_loss])\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "        if iter % batch_size:\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            loss = 0\n",
    "\n",
    "    # showPlot(plot_losses)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(input_dim, emb_dim, hid_dim, n_layers, dropout).to(device)\n",
    "attn_decoder = AttnDecoderLSTM(output_dim, hid_dim, hid_dim, n_layers, dropout, MAX_LENGTH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 25s (- 213m 29s) (100 0%) train: 8.9125 dev: 7.7972\n",
      "3m 32s (- 261m 31s) (200 1%) train: 6.7749 dev: 6.5390\n",
      "5m 37s (- 275m 30s) (300 2%) train: 6.1857 dev: 5.7561\n",
      "7m 43s (- 281m 58s) (400 2%) train: 5.6621 dev: 5.5736\n",
      "9m 51s (- 286m 4s) (500 3%) train: 5.9334 dev: 5.6216\n",
      "11m 56s (- 286m 35s) (600 4%) train: 5.3471 dev: 5.2093\n",
      "14m 5s (- 287m 43s) (700 4%) train: 5.3117 dev: 5.1270\n",
      "16m 12s (- 287m 47s) (800 5%) train: 5.0588 dev: 5.0043\n",
      "18m 14s (- 285m 43s) (900 6%) train: 4.8448 dev: 4.9164\n",
      "20m 11s (- 282m 35s) (1000 6%) train: 5.0260 dev: 5.1612\n",
      "22m 8s (- 279m 53s) (1100 7%) train: 4.8724 dev: 4.7910\n",
      "24m 11s (- 278m 9s) (1200 8%) train: 4.7923 dev: 4.7703\n",
      "26m 10s (- 275m 54s) (1300 8%) train: 4.7942 dev: 4.6463\n",
      "28m 13s (- 274m 6s) (1400 9%) train: 4.6441 dev: 4.6719\n",
      "30m 13s (- 271m 57s) (1500 10%) train: 4.7660 dev: 4.6420\n",
      "32m 10s (- 269m 26s) (1600 10%) train: 4.6134 dev: 4.5838\n",
      "34m 9s (- 267m 11s) (1700 11%) train: 4.6917 dev: 4.5280\n",
      "36m 9s (- 265m 10s) (1800 12%) train: 4.5222 dev: 4.5071\n",
      "38m 8s (- 263m 0s) (1900 12%) train: 4.5316 dev: 4.7110\n",
      "40m 10s (- 261m 7s) (2000 13%) train: 4.5591 dev: 4.4720\n",
      "42m 9s (- 258m 57s) (2100 14%) train: 4.2938 dev: 4.5384\n",
      "44m 9s (- 256m 57s) (2200 14%) train: 4.4930 dev: 4.4285\n",
      "46m 7s (- 254m 39s) (2300 15%) train: 4.2951 dev: 4.3874\n",
      "48m 7s (- 252m 40s) (2400 16%) train: 4.4111 dev: 4.4053\n",
      "50m 7s (- 250m 35s) (2500 16%) train: 4.2387 dev: 4.3423\n",
      "52m 8s (- 248m 39s) (2600 17%) train: 4.1265 dev: 4.3332\n",
      "54m 8s (- 246m 37s) (2700 18%) train: 4.0960 dev: 4.3858\n",
      "56m 7s (- 244m 34s) (2800 18%) train: 4.3290 dev: 4.2862\n",
      "58m 6s (- 242m 25s) (2900 19%) train: 4.4416 dev: 4.2624\n",
      "60m 6s (- 240m 24s) (3000 20%) train: 4.2906 dev: 4.2452\n",
      "62m 7s (- 238m 28s) (3100 20%) train: 4.3819 dev: 4.2781\n",
      "64m 8s (- 236m 30s) (3200 21%) train: 4.3199 dev: 4.2141\n",
      "66m 14s (- 234m 52s) (3300 22%) train: 4.1531 dev: 4.2368\n",
      "68m 18s (- 233m 4s) (3400 22%) train: 4.1657 dev: 4.2026\n",
      "70m 26s (- 231m 27s) (3500 23%) train: 4.1381 dev: 4.2562\n",
      "72m 31s (- 229m 38s) (3600 24%) train: 4.0526 dev: 4.2399\n",
      "74m 35s (- 227m 48s) (3700 24%) train: 3.9303 dev: 4.1757\n",
      "76m 43s (- 226m 8s) (3800 25%) train: 3.9698 dev: 4.1803\n",
      "78m 50s (- 224m 24s) (3900 26%) train: 4.0417 dev: 4.2048\n",
      "80m 57s (- 222m 36s) (4000 26%) train: 4.0748 dev: 4.1702\n",
      "83m 1s (- 220m 42s) (4100 27%) train: 4.0607 dev: 4.1164\n",
      "85m 7s (- 218m 53s) (4200 28%) train: 4.2054 dev: 4.1378\n",
      "87m 14s (- 217m 5s) (4300 28%) train: 4.0228 dev: 4.1037\n",
      "89m 20s (- 215m 13s) (4400 29%) train: 3.9039 dev: 4.1176\n",
      "91m 29s (- 213m 29s) (4500 30%) train: 3.9707 dev: 4.0969\n",
      "93m 33s (- 211m 31s) (4600 30%) train: 4.3009 dev: 4.1315\n",
      "95m 38s (- 209m 36s) (4700 31%) train: 4.0901 dev: 4.0766\n",
      "97m 46s (- 207m 46s) (4800 32%) train: 4.0128 dev: 4.1041\n",
      "99m 52s (- 205m 51s) (4900 32%) train: 4.1453 dev: 4.0913\n",
      "101m 57s (- 203m 55s) (5000 33%) train: 3.8842 dev: 4.0750\n",
      "104m 3s (- 202m 0s) (5100 34%) train: 3.9604 dev: 4.0159\n",
      "106m 12s (- 200m 9s) (5200 34%) train: 3.9546 dev: 4.0637\n",
      "108m 19s (- 198m 15s) (5300 35%) train: 4.0576 dev: 4.0168\n",
      "110m 22s (- 196m 14s) (5400 36%) train: 4.0348 dev: 4.0158\n",
      "112m 25s (- 194m 11s) (5500 36%) train: 3.8780 dev: 3.9923\n",
      "114m 26s (- 192m 5s) (5600 37%) train: 4.0805 dev: 4.0324\n",
      "116m 26s (- 189m 59s) (5700 38%) train: 3.8947 dev: 4.0129\n",
      "118m 27s (- 187m 53s) (5800 38%) train: 3.7274 dev: 4.0483\n",
      "120m 28s (- 185m 48s) (5900 39%) train: 4.1849 dev: 4.0012\n",
      "122m 29s (- 183m 44s) (6000 40%) train: 3.9843 dev: 4.0193\n",
      "124m 30s (- 181m 40s) (6100 40%) train: 3.7252 dev: 3.9774\n",
      "126m 26s (- 179m 28s) (6200 41%) train: 3.8258 dev: 3.9978\n",
      "128m 25s (- 177m 21s) (6300 42%) train: 3.8397 dev: 3.9474\n",
      "130m 26s (- 175m 17s) (6400 42%) train: 3.9538 dev: 3.9663\n",
      "132m 24s (- 173m 9s) (6500 43%) train: 3.8181 dev: 3.9586\n",
      "134m 25s (- 171m 4s) (6600 44%) train: 3.9905 dev: 3.9922\n",
      "136m 24s (- 168m 59s) (6700 44%) train: 3.5762 dev: 3.9479\n",
      "138m 22s (- 166m 52s) (6800 45%) train: 3.8450 dev: 3.9449\n",
      "140m 23s (- 164m 48s) (6900 46%) train: 3.9064 dev: 3.9258\n",
      "142m 23s (- 162m 43s) (7000 46%) train: 3.8554 dev: 3.9194\n",
      "144m 22s (- 160m 38s) (7100 47%) train: 3.9886 dev: 3.9250\n",
      "146m 22s (- 158m 34s) (7200 48%) train: 3.8260 dev: 3.9450\n",
      "148m 23s (- 156m 30s) (7300 48%) train: 3.9359 dev: 3.9030\n",
      "150m 24s (- 154m 28s) (7400 49%) train: 3.5213 dev: 3.9373\n",
      "152m 23s (- 152m 23s) (7500 50%) train: 3.8712 dev: 3.9139\n",
      "154m 24s (- 150m 20s) (7600 50%) train: 3.8781 dev: 3.9047\n",
      "156m 25s (- 148m 17s) (7700 51%) train: 3.7589 dev: 3.8948\n",
      "158m 27s (- 146m 16s) (7800 52%) train: 3.8425 dev: 3.9445\n",
      "160m 29s (- 144m 14s) (7900 52%) train: 3.8668 dev: 3.8738\n",
      "162m 34s (- 142m 15s) (8000 53%) train: 3.7795 dev: 3.9179\n",
      "164m 40s (- 140m 16s) (8100 54%) train: 3.7546 dev: 3.8926\n",
      "166m 44s (- 138m 16s) (8200 54%) train: 3.8198 dev: 3.8809\n",
      "168m 47s (- 136m 15s) (8300 55%) train: 3.6451 dev: 3.8744\n",
      "170m 53s (- 134m 16s) (8400 56%) train: 3.7867 dev: 3.8841\n",
      "172m 58s (- 132m 16s) (8500 56%) train: 3.6267 dev: 3.8700\n",
      "175m 3s (- 130m 16s) (8600 57%) train: 3.7987 dev: 3.8553\n",
      "177m 9s (- 128m 17s) (8700 57%) train: 3.8896 dev: 3.8742\n",
      "179m 15s (- 126m 17s) (8800 58%) train: 3.8261 dev: 3.8339\n",
      "181m 18s (- 124m 16s) (8900 59%) train: 3.9723 dev: 3.8281\n",
      "183m 24s (- 122m 16s) (9000 60%) train: 3.7011 dev: 3.8638\n",
      "185m 28s (- 120m 15s) (9100 60%) train: 3.7840 dev: 3.8368\n",
      "187m 34s (- 118m 15s) (9200 61%) train: 3.7245 dev: 3.8206\n",
      "189m 38s (- 116m 14s) (9300 62%) train: 3.6886 dev: 3.8198\n",
      "191m 44s (- 114m 13s) (9400 62%) train: 3.6936 dev: 3.8441\n",
      "193m 49s (- 112m 12s) (9500 63%) train: 3.6149 dev: 3.8142\n",
      "195m 53s (- 110m 11s) (9600 64%) train: 3.5589 dev: 3.8086\n",
      "197m 57s (- 108m 9s) (9700 64%) train: 3.7232 dev: 3.8154\n",
      "200m 1s (- 106m 8s) (9800 65%) train: 3.7901 dev: 3.8115\n",
      "202m 3s (- 104m 5s) (9900 66%) train: 3.6246 dev: 3.8121\n",
      "204m 5s (- 102m 2s) (10000 66%) train: 3.6537 dev: 3.8382\n",
      "206m 12s (- 100m 2s) (10100 67%) train: 3.6950 dev: 3.8322\n",
      "208m 18s (- 98m 1s) (10200 68%) train: 3.5690 dev: 3.8557\n",
      "210m 18s (- 95m 57s) (10300 68%) train: 3.8030 dev: 3.8019\n",
      "212m 19s (- 93m 54s) (10400 69%) train: 3.7293 dev: 3.8021\n",
      "214m 17s (- 91m 50s) (10500 70%) train: 3.5426 dev: 3.7998\n",
      "216m 15s (- 89m 46s) (10600 70%) train: 3.7923 dev: 3.7713\n",
      "218m 15s (- 87m 42s) (10700 71%) train: 3.7153 dev: 3.8079\n",
      "220m 14s (- 85m 38s) (10800 72%) train: 3.5963 dev: 3.8611\n",
      "222m 15s (- 83m 36s) (10900 72%) train: 3.5845 dev: 3.7796\n",
      "224m 15s (- 81m 32s) (11000 73%) train: 3.8674 dev: 3.7642\n",
      "226m 11s (- 79m 28s) (11100 74%) train: 3.6681 dev: 3.8021\n",
      "228m 7s (- 77m 24s) (11200 74%) train: 3.8178 dev: 3.8034\n",
      "230m 7s (- 75m 21s) (11300 75%) train: 3.6825 dev: 3.8033\n",
      "232m 8s (- 73m 18s) (11400 76%) train: 3.7622 dev: 3.8145\n",
      "234m 5s (- 71m 14s) (11500 76%) train: 3.6021 dev: 3.7530\n",
      "236m 3s (- 69m 11s) (11600 77%) train: 3.5481 dev: 3.7638\n",
      "238m 1s (- 67m 8s) (11700 78%) train: 3.4950 dev: 3.7672\n",
      "240m 3s (- 65m 5s) (11800 78%) train: 3.8601 dev: 3.7575\n",
      "242m 2s (- 63m 3s) (11900 79%) train: 3.6306 dev: 3.7632\n",
      "244m 3s (- 61m 0s) (12000 80%) train: 3.5618 dev: 3.7528\n",
      "246m 0s (- 58m 57s) (12100 80%) train: 3.7130 dev: 3.7741\n",
      "248m 1s (- 56m 55s) (12200 81%) train: 3.5849 dev: 3.7287\n",
      "250m 3s (- 54m 53s) (12300 82%) train: 3.4854 dev: 3.7431\n",
      "252m 1s (- 52m 50s) (12400 82%) train: 3.6292 dev: 3.7528\n",
      "254m 1s (- 50m 48s) (12500 83%) train: 3.7823 dev: 3.7375\n",
      "256m 1s (- 48m 45s) (12600 84%) train: 3.5007 dev: 3.7604\n",
      "258m 2s (- 46m 43s) (12700 84%) train: 3.7132 dev: 3.7379\n",
      "260m 7s (- 44m 42s) (12800 85%) train: 3.5275 dev: 3.7690\n",
      "262m 12s (- 42m 41s) (12900 86%) train: 3.5305 dev: 3.7336\n",
      "264m 15s (- 40m 39s) (13000 86%) train: 3.4743 dev: 3.7087\n",
      "266m 18s (- 38m 37s) (13100 87%) train: 3.7025 dev: 3.7367\n",
      "268m 22s (- 36m 35s) (13200 88%) train: 3.6854 dev: 3.7195\n",
      "270m 26s (- 34m 34s) (13300 88%) train: 3.7162 dev: 3.7152\n",
      "272m 28s (- 32m 32s) (13400 89%) train: 3.6328 dev: 3.7130\n",
      "274m 32s (- 30m 30s) (13500 90%) train: 3.6101 dev: 3.7262\n",
      "276m 37s (- 28m 28s) (13600 90%) train: 3.5782 dev: 3.7292\n",
      "278m 40s (- 26m 26s) (13700 91%) train: 3.5264 dev: 3.7449\n",
      "280m 46s (- 24m 24s) (13800 92%) train: 3.6336 dev: 3.7096\n",
      "282m 52s (- 22m 23s) (13900 92%) train: 3.5518 dev: 3.7309\n",
      "284m 55s (- 20m 21s) (14000 93%) train: 3.5573 dev: 3.7064\n",
      "287m 0s (- 18m 19s) (14100 94%) train: 3.5469 dev: 3.7287\n",
      "289m 4s (- 16m 17s) (14200 94%) train: 3.7250 dev: 3.7106\n",
      "291m 9s (- 14m 15s) (14300 95%) train: 3.6085 dev: 3.7112\n",
      "293m 16s (- 12m 13s) (14400 96%) train: 3.5549 dev: 3.7130\n",
      "295m 19s (- 10m 11s) (14500 96%) train: 3.3959 dev: 3.7066\n",
      "297m 26s (- 8m 8s) (14600 97%) train: 3.5508 dev: 3.7633\n",
      "299m 31s (- 6m 6s) (14700 98%) train: 3.7086 dev: 3.7059\n",
      "301m 34s (- 4m 4s) (14800 98%) train: 3.5232 dev: 3.7189\n",
      "303m 40s (- 2m 2s) (14900 99%) train: 3.6149 dev: 3.6970\n",
      "305m 42s (- 0m 0s) (15000 100%) train: 3.4068 dev: 3.6875\n"
     ]
    }
   ],
   "source": [
    "att_train_process = trainIters_attn(encoder, attn_decoder, 15000, print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = torch.load('encoder2.pt')\n",
    "# attn_decoder = torch.load('decoder2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder,'encoder2.pt')\n",
    "torch.save(attn_decoder,'decoder2.pt')\n",
    "\n",
    "f = open(\"att_train_process.txt\", 'w+')\n",
    "for p in att_train_process:\n",
    "    f.write(str(p[0])+ ' ' + str(p[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attn(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden, encoder_cell = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hid_dim, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden, encoder_cell)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly_attn(encoder, decoder, n=2):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attention= evaluate_attn(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ingredients: 1    four-pound chicken\t2 c  carrots, diced\t1 c  celery, diced\t1/4 c  cooking fat\t1/2 c  minced onion\t1 c  milk\t1 c  hot water\tsalt and pepper\t1    green pepper, chopped\tflour\n",
      "\n",
      "= cut chicken pieces . dredge with flour . brown in hot cooking fat . season with salt and pepper . place chicken in casserole . add water . cover . cook slowly until chicken is tender . add vegetables which have been browned in the cooking fat . cover . cook slowly until vegetables are tender . add water if necessary . remove chicken . combine milk and 2 tablespoons flour . mix until smooth . combine with vegetables and chicken broth . cook slowly , stirring constantly until smooth . serve with chicken . 8 servings . mrs. m. westrum , scarville , ia . \n",
      "< in a large bowl , combine all ingredients except cheese . in a bowl , combine flour , baking powder and salt . add flour and mix well . pour into greased muffin tins . bake at 350 degrees for 20 minutes .  <EOS>\n",
      "\n",
      "> ingredients: 1 pk sugar-free gelatin; any\t1/4 ts cinnamon flavor (4 serving size box)             mint\t3/4 c  -water; boiling\tapple;sliced thin\t1 3/4 c  applesauce; unsweetened but\tcinnamon sticks well chilled                  \n",
      "\n",
      "= prepare gelatin as usual using the applesauce instead of cold water . chill . garnish with a mint sprig , thin slices of apple and a small cinnamon stick . \n",
      "< in a large bowl , combine flour , sugar , baking powder and salt . add flour , and mix well . add flour and mix well . add flour and mix well . add water , stirring constantly . pour into greased loaf pan . bake at 350 degrees for 20 minutes .  <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly_attn(encoder, attn_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "att_train_process = np.array(att_train_process)\n",
    "train_process = np.array(train_process)\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "x = [100 * (1 + i) for i in range(len(att_train_process))]\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(x, train_process[:,0], label = 'train loss')\n",
    "plt.plot(x, train_process[:,1], label = 'dev loss')\n",
    "plt.plot(x, att_train_process[:,0], label = 'att train loss')\n",
    "plt.plot(x, att_train_process[:,1], label = 'att dev loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantitative_Evaluation(encoder, decoder, atten):\n",
    "    bleu_score = 0\n",
    "    for x, y in pairs_test:\n",
    "        if atten:\n",
    "            y_, a = evaluate_attn(encoder, decoder, x)\n",
    "        else:\n",
    "            y_ = evaluate(encoder, decoder, x)\n",
    "        y = y.split(' ')\n",
    "        bleu_score += nltk.translate.bleu_score.sentence_bleu(y_, y, smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method1)\n",
    "\n",
    "    merteor_score  = 0\n",
    "    for x, y in pairs_test:\n",
    "        if atten:\n",
    "            y_, a = evaluate_attn(encoder, decoder, x)\n",
    "        else:\n",
    "            y_ = evaluate(encoder, decoder, x)\n",
    "        y = y.split(' ')\n",
    "        merteor_score  += nltk.translate.meteor_score.single_meteor_score(y_, y)\n",
    "    \n",
    "    avg_given  = 0\n",
    "    avg_extra  = 0\n",
    "    for x, y in pairs_test:\n",
    "        if atten:\n",
    "            y_, a = evaluate_attn(encoder, decoder, x)\n",
    "        else:\n",
    "            y_ = evaluate(encoder, decoder, x)\n",
    "        y = y.split(' ')\n",
    "        y = set(y)\n",
    "        y_ = set(y_)\n",
    "        avg_given += len(y_ & y) / len(y_)\n",
    "        avg_extra += len(y_ - y)\n",
    "        \n",
    "    print(avg_given /len(pairs_test))\n",
    "    print(avg_extra /len(pairs_test))\n",
    "    print(merteor_score /len(pairs_test))\n",
    "    print(bleu_score/len(pairs_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.376930090143357\n",
      "15.571428571428571\n",
      "0.2481440169662675\n",
      "0.004453949840304741\n"
     ]
    }
   ],
   "source": [
    "Quantitative_Evaluation(encoder1, decoder1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3755736051085988\n",
      "18.159147869674186\n",
      "0.23120818253495834\n",
      "0.00461299991025577\n"
     ]
    }
   ],
   "source": [
    "Quantitative_Evaluation(encoder, attn_decoder, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in a large bowl , combine the remaining ingredients . mix well . add the remaining ingredients . cover and simmer for 30 minutes . remove from heat . add the rice and stir . add the rice and cook until the rice is tender . add the rice and stir . cover and simmer for 5 minutes . remove from heat . stir in the remaining ingredients . cover and simmer for 30 minutes . remove the bay leaf and serve .  <EOS>\n"
     ]
    }
   ],
   "source": [
    "sentence = \"10 oz chopped broccoli, 2 tbsp butter, 2 tbsp flour, 1/2 tsp salt, 1/4 tsp black pepper, 1/4 tsp ground nutmeg, 1 cup milk, 1 1/2 cup shredded swiss cheese, 2 tsp lemon juice, 2 cup cooked cubed turkey, 4 oz mushrooms, 1/4 cup grated cheese, 1 can refrigerated biscuits\"\n",
    "\n",
    "output_words= evaluate(encoder1, decoder1, sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in a large bowl , combine the sugar , sugar , cinnamon , cinnamon , nutmeg , and nutmeg . mix well . add the flour , baking powder and salt . stir in the flour , baking powder and salt . stir in the flour . bring to a boil . remove from heat and stir in the nuts . pour over the cake . bake in a preheated oven for 30 minutes .  <EOS>\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ingredients: 2 lb cream cheese, 1 3/4 cups sugar, 5 eggs, 15 oreo cookies, 1/2 tsp vanilla, 1/2 tsp almond extract\"\n",
    "\n",
    "output_words= evaluate(encoder1, decoder1, sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in a large bowl , combine all ingredients except the oil . add the flour and mix well . add the flour and mix well . add the flour and mix well . add the flour and mix well . add the flour and mix well . add the milk and mix well . add the flour and mix well . add the flour and mix well . add the flour and mix well . add the flour and mix well . add the flour and mix well . add the egg yolks , one at a time , beating well after each addition . pour into a greased 9 x 13 x 9 x 13 pan . bake at 350 degrees for 20 minutes .  <EOS>\n"
     ]
    }
   ],
   "source": [
    "sentence = \"10 oz chopped broccoli, 2 tbsp butter, 2 tbsp flour, 1/2 tsp salt, 1/4 tsp black pepper, 1/4 tsp ground nutmeg, 1 cup milk, 1 1/2 cup shredded swiss cheese, 2 tsp lemon juice, 2 cup cooked cubed turkey, 4 oz mushrooms, 1/4 cup grated cheese, 1 can refrigerated biscuits\"\n",
    "\n",
    "output_words, output_attention = evaluate_attn(encoder1, attn_decoder, sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in a large bowl , combine all ingredients except the oil in a bowl . add the oil and mix well . add the water and stir . add the water and let stand for 5 minutes . add the water and let stand for 10 minutes . add the water and let stand for 5 minutes . add the water and let stand for 5 minutes . add the water and let stand for 5 minutes . add the water and let stand for 5 minutes . add the water and let stand for 10 minutes . add the remaining ingredients and mix well . pour into a serving dish and serve hot .  <EOS>\n"
     ]
    }
   ],
   "source": [
    "sentence = \" 2 lb cream cheese, 1 3/4 cups sugar, 5 eggs, 15 oreo cookies, 1/2 tsp vanilla, 1/2 tsp almond extract\"\n",
    "\n",
    "output_words, output_attention = evaluate_attn(encoder, attn_decoder, sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print(output_sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
